{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "import re, string\n",
    "from collections import Counter\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats.stats import pearsonr\n",
    "import readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation, multiple spaces and stopwords\n",
    "def data_preprocess(input_df, stop_word = True):\n",
    "    new_wopunc = input_df.str.replace('[^\\w\\s]',' ')\n",
    "    if stop_word:\n",
    "        stop_words = r'\\b(?:{})\\b'.format('|'.join(set(stopwords.words('english'))))\n",
    "        new_wostw = new_wopunc.str.lower().str.replace(stop_words, ' ')\n",
    "        New = new_wostw.str.replace('\\s+', ' ', regex=True)\n",
    "    else:\n",
    "        New = new_wopunc.str.lower().str.replace('\\s+', ' ', regex=True)\n",
    "    return New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the features\n",
    "# Maximum repetition of unigrams\n",
    "def max_rep_uni(input_s):\n",
    "    max_rep_uni= pd.Series(map(lambda x: max(Counter(x).values()), filter(None, input_s.str.split(' '))))\n",
    "    return max_rep_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the features\n",
    "# Maximum repetition of bigrams\n",
    "def max_rep_bi(input_s):\n",
    "    max_rep_bi = pd.Series(map(lambda x: max(Counter(list(nltk.bigrams(x))).values()), filter(None, input_s.str.split(' '))))\n",
    "    return max_rep_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate word2vec representation of the reviews \n",
    "def word2vec_embedding(input_s, vec_pre):\n",
    "    vec = []\n",
    "    for i in range(len(input_s)):\n",
    "        l = [w for w in input_s[i].split(' ') if w in vec_pre]\n",
    "        if len(l)>0:\n",
    "            vec_l = []\n",
    "            for j in range(len(l)):\n",
    "                vec_l.append(vec_pre[l[j]])\n",
    "            vec_l = sum(vec_l)/len(vec_l)\n",
    "            vec.append(vec_l)\n",
    "    return pd.Series(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the features\n",
    "# Maximum Similarity of sentences\n",
    "def max_sim(input_s):\n",
    "    l = pd.Series(map(lambda x:pd.Series( nltk.sent_tokenize(x)), input_s))\n",
    "    sos = pd.Series(map(data_preprocess,l))\n",
    "    l_0 = list(map(lambda x: pd.Series(x.replace(' ', np.nan, inplace=True)), sos))\n",
    "    sos_cl = pd.Series(map(lambda x: pd.Series(x.dropna().reset_index(drop=True)), sos))\n",
    "    word_rep = pd.Series(map(lambda x: word2vec_embedding(x, word2vec), sos_cl))\n",
    "    max_s = []\n",
    "    for i in range(len(word_rep)):\n",
    "        \n",
    "        if len(word_rep[i]) == 1:\n",
    "            max_s.append(1)\n",
    "        else:\n",
    "            cos = []\n",
    "            for j in range(len(word_rep[i])):\n",
    "                for k in range(len(word_rep[i])):\n",
    "                    if j != k:\n",
    "                        cos.append(cosine_similarity([word_rep[i][j],word_rep[i][k]])[0][1])\n",
    "            max_s.append(max(cos))\n",
    "    return max_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocess and Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read files\n",
    "train_df=pd.read_csv(\"./Train_Data.csv\")\n",
    "test_df=pd.read_csv(\"./Test_Data.csv\",encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzip the file to word directory\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['New Summary'] = data_preprocess(train_df['Summary'])\n",
    "train_df['max_rep_uni'] = max_rep_uni(train_df['New Summary'])\n",
    "train_df['max_rep_bi'] = max_rep_bi(train_df['New Summary'])\n",
    "train_df['max_sim'] = max_sim(train_df['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['New Summary'] = data_preprocess(test_df['Summary'])\n",
    "test_df['max_rep_uni'] = max_rep_uni(test_df['New Summary'])\n",
    "test_df['max_rep_bi'] = max_rep_bi(test_df['New Summary'])\n",
    "test_df['max_sim'] = max_sim(test_df['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(train_df[['max_rep_uni','max_rep_bi', 'max_sim']], train_df['Non-Redundancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(test_df[['max_rep_uni','max_rep_bi', 'max_sim']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.21356612418283025.\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(test_df['Non-Redundancy'], pred)\n",
    "print(\"MSE is %s.\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient is 0.6880791212152372.\n"
     ]
    }
   ],
   "source": [
    "p_cor = pearsonr(test_df['Non-Redundancy'], pred)\n",
    "print(\"Pearson coefficient is %s.\" % p_cor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the features\n",
    "# Number of stopwords\n",
    "def count_stw(l):\n",
    "    c = 0\n",
    "    for i in range(len(l)):\n",
    "        if l[i] in set(stopwords.words('english')):\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def num_stw(input_s):\n",
    "    numstw = pd.Series(map(count_stw,filter(None, input_s.str.split(' '))))\n",
    "    return numstw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique words\n",
    "def num_uni(input_s):\n",
    "    num_uni = pd.Series(map(lambda x:len(Counter(x)),filter(None, input_s.str.split(' '))))\n",
    "    return num_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate features 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['New_Summary_w_sw'] = data_preprocess(train_df['Summary'], stop_word = False)\n",
    "test_df['New_Summary_w_sw'] = data_preprocess(test_df['Summary'], stop_word = False)\n",
    "train_df['numstw'] = num_stw(train_df['New_Summary_w_sw'])\n",
    "test_df['numstw'] = num_stw(test_df['New_Summary_w_sw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(train_df[['max_rep_uni','max_rep_bi', 'max_sim','numstw']], train_df['Non-Redundancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(test_df[['max_rep_uni','max_rep_bi', 'max_sim','numstw']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.22434490250489547.\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(test_df['Non-Redundancy'], pred)\n",
    "print(\"MSE is %s.\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient is 0.6660487180073126.\n"
     ]
    }
   ],
   "source": [
    "p_cor = pearsonr(test_df['Non-Redundancy'], pred)\n",
    "print(\"Pearson coefficient is %s.\" % p_cor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0730213 , -0.1701772 , -1.86224303,  0.00975268])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was not improved when adding Number of stopwords. \n",
    "The Number of stopwords was expected to have negative impact on non-redundency. \n",
    "But the model shows a very small positive coefficient for this feature and model was not improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate features 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['numuni'] = num_uni(train_df['New Summary'])\n",
    "test_df['numuni'] = num_uni(test_df['New Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(train_df[['max_rep_uni','max_rep_bi', 'max_sim','numuni']], train_df['Non-Redundancy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(test_df[['max_rep_uni','max_rep_bi', 'max_sim','numuni']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.19838644426870203.\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(test_df['Non-Redundancy'], pred)\n",
    "print(\"MSE is %s.\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient is 0.7089801217174854.\n"
     ]
    }
   ],
   "source": [
    "p_cor = pearsonr(test_df['Non-Redundancy'], pred)\n",
    "print(\"Pearson coefficient is %s.\" % p_cor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07959178, -0.1436767 , -1.6476043 ,  0.01932475])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was improved when adding Number of unique words. \n",
    "\n",
    "MSE from 0.214 to 0.198\n",
    "\n",
    "P_cor from 0.688 to 0.709\n",
    "\n",
    "This is reasonable because the more uniques words used, the more meaningful and the less redundency the summary is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate feature\n",
    "#Total number of repetitive unigrams\n",
    "def count_rep_uni(input_list):\n",
    "    c=0\n",
    "    for i in range(len(input_list)-1):\n",
    "        if input_list[i] == input_list[i+1]:\n",
    "            c +=1\n",
    "    return c\n",
    "\n",
    "def rep_uni(input_s):\n",
    "    l = list(filter(None, input_s.str.split(' ')))\n",
    "    rep_uni = pd.Series(list(map(count_rep_uni, l)))\n",
    "    return rep_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of repetitive bigrams\n",
    "def count_rep_bi(input_list):\n",
    "    c=0\n",
    "    for i in range(len(input_list)-2):\n",
    "        if input_list[i] == input_list[i+2]:\n",
    "            c +=1\n",
    "    return c\n",
    "\n",
    "def rep_bi(input_s):\n",
    "    l = list(map(lambda x: list(nltk.bigrams(x)), filter(None, input_s.str.split(' '))))\n",
    "    rep_bi = pd.Series(list(map(count_rep_bi, l)))\n",
    "    return rep_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readability score \n",
    "def read_score(input_s):\n",
    "    l = pd.Series(map(lambda x:pd.Series( nltk.sent_tokenize(x)), input_s))\n",
    "    sos = pd.Series(map(data_preprocess,l))\n",
    "    l_0 = list(map(lambda x: pd.Series(x.replace(' ', np.nan, inplace=True)), sos))\n",
    "    sos_cl = pd.Series(map(lambda x: pd.Series(x.dropna().reset_index(drop=True)), sos))\n",
    "    read_score = []\n",
    "    for i in range(len(sos_cl)):\n",
    "        sc = min(list(map(lambda x: readability.getmeasures(x, lang='en')['readability grades']['FleschReadingEase'], sos_cl[i])))\n",
    "        read_score.append(sc)\n",
    "    return read_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['rep_uni'] = rep_uni(train_df['New_Summary_w_sw'])\n",
    "train_df['rep_bi'] = rep_bi(train_df['New_Summary_w_sw'])\n",
    "train_df['read_score'] = read_score(train_df['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['rep_uni'] = rep_uni(test_df['New_Summary_w_sw'])\n",
    "test_df['rep_bi'] = rep_bi(test_df['New_Summary_w_sw'])\n",
    "test_df['read_score'] = read_score(test_df['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_fl = LinearRegression().fit(train_df[['rep_uni', 'rep_bi', 'read_score']], train_df['Fluency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fl = reg_fl.predict(test_df[['rep_uni', 'rep_bi', 'read_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.24180648384915657.\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(test_df['Fluency'], pred_fl)\n",
    "print(\"MSE is %s.\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient is 0.28167521957654607.\n"
     ]
    }
   ],
   "source": [
    "p_cor = pearsonr(test_df['Fluency'], pred_fl)\n",
    "print(\"Pearson coefficient is %s.\" % p_cor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of sentences\n",
    "def num_sen(input_s):\n",
    "    l = pd.Series(map(lambda x:pd.Series( nltk.sent_tokenize(x)), input_s))\n",
    "    num_sen = pd.Series(map(len,l))\n",
    "    return num_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count preposition from a pos_tag list\n",
    "def count_p(inputlist):\n",
    "    c = 0\n",
    "    for i in range(len(inputlist)):\n",
    "        if inputlist[i][1][0:2] == 'IN':\n",
    "            c += 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of Preps\n",
    "def num_prep(input_s):\n",
    "    l = pd.Series(map(lambda x:pd.Series(nltk.pos_tag(nltk.word_tokenize(x))), input_s))\n",
    "    num_verb = pd.Series(map(count_p,l))\n",
    "    return num_verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate features 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['numsen'] = num_sen(train_df['Summary'])\n",
    "test_df['numsen'] = num_sen(test_df['Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_fl = LinearRegression().fit(train_df[['rep_uni', 'rep_bi','read_score','numsen']], train_df['Fluency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fl = reg_fl.predict(test_df[['rep_uni', 'rep_bi','read_score','numsen']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.24771596926819606.\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(test_df['Fluency'], pred_fl)\n",
    "print(\"MSE is %s.\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient is 0.30348022383819573.\n"
     ]
    }
   ],
   "source": [
    "p_cor = pearsonr(test_df['Fluency'], pred_fl)\n",
    "print(\"Pearson coefficient is %s.\" % p_cor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16522268, -0.02911817,  0.00020206,  0.02909331])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_fl.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was not improved when adding number of sentences. \n",
    "The number of sentences was expected to have positive impact on fluency. \n",
    "The model shows a positive coefficient for this feature but the model was not improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate features 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['numprep'] = num_prep(train_df['New Summary'])\n",
    "test_df['numprep'] = num_prep(test_df['New Summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_fl = LinearRegression().fit(train_df[['rep_uni', 'rep_bi','read_score','numprep']], train_df['Fluency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fl = reg_fl.predict(test_df[['rep_uni', 'rep_bi','read_score','numprep']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 0.2391553399924169.\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(test_df['Fluency'], pred_fl)\n",
    "print(\"MSE is %s.\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient is 0.3004648103413536.\n"
     ]
    }
   ],
   "source": [
    "p_cor = pearsonr(test_df['Fluency'], pred_fl)\n",
    "print(\"Pearson coefficient is %s.\" % p_cor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was improved when adding num of Prepositions. \n",
    "\n",
    "MSE from 0.242 to 0.239\n",
    "\n",
    "P_cor from 0.282 to 0.300\n",
    "\n",
    "This is reasonable because the more prepositions used, the more fluent the sentences are."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
